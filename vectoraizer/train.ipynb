{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!python --version"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvlMkRlrgX3t",
    "outputId": "2f9957b7-2ddc-4946-d1db-7285c30bd7ed"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath('../')\n",
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from vectoraizer.shapes import shapes_types, shapes_classes\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'logs')\n",
    "\n",
    "%tensorboard --logdir $MODEL_DIR --port=8009\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'mask_rcnn_coco.h5')\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TL0ddR8Nr_5J",
    "outputId": "c2e00383-3bac-4f5d-b22e-90c3bfa7b1d8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CD4WkRtjfGA"
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om2CNzvojfGA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "59a17a06-aa99-4371-f5d6-0a2f91ee73df"
   },
   "outputs": [],
   "source": [
    "class ShapesConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = 'shapes'\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + len(shapes_types)  # background + number of shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    USE_MINI_MASK = False\n",
    "    RUN_EAGERLY = False\n",
    "\n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot-BDR9OjfGB"
   },
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "sKWFCtMJjfGC"
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "\n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s41sVP5RjfGD"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WbzTHG-ijfGD"
   },
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"\n",
    "    Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (ellipses, triangles, rectangles, pentagons) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        for shape_id, shape in enumerate(shapes_types):\n",
    "            self.add_class('shapes', shape_id, shape.name)\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image('shapes', image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id, with_bbox = False):\n",
    "        \"\"\"\n",
    "        Generate an image from the specs of the given image ID.\n",
    "        Typically, this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        _image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        _image = _image * bg_color.astype(np.uint8)\n",
    "        for shape in info['shapes']:\n",
    "            _image = self.draw_shape(_image, shape, with_bbox=with_bbox)\n",
    "\n",
    "        # JPEG encode with quality variable between 80% and 100%\n",
    "        # to improve resilience to compression artifacts\n",
    "        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), np.random.randint(80, 100)]\n",
    "        _, encoded_image = np.array(cv2.imencode('.jpg', _image, encode_param))\n",
    "        _image = cv2.imdecode(encoded_image, cv2.IMREAD_COLOR)\n",
    "        return _image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info['source'] == 'shapes':\n",
    "            return info['shapes']\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        masks = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, shape in enumerate(info['shapes']):\n",
    "            masks[:, :, i:i + 1] = self.draw_shape(masks[:, :, i:i + 1].copy(), shape, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(masks[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            masks[:, :, i] = masks[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(masks[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        _class_ids = np.array([self.class_names.index(s.name) for s in shapes])\n",
    "        return masks.astype(np.bool), _class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, canvas, shape, color=None, with_bbox=False):\n",
    "        \"\"\"Draws a shape from the given specs\"\"\"\n",
    "        return shape.draw(canvas, color, with_bbox)\n",
    "\n",
    "    def generate_random_shape(self, image_height, image_width):\n",
    "        \"\"\"\n",
    "        Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_width: int\n",
    "        image_height: int\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Shape\n",
    "        \"\"\"\n",
    "        shape_name = random.choice(list(map(lambda cl: cl['name'], self.class_info[1:])))\n",
    "        return shapes_classes[shape_name].generate(image_width, image_height)\n",
    "\n",
    "    def random_image(self, image_height, image_width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        shapes_count = random.randint(1, 10)\n",
    "        for _ in range(shapes_count):\n",
    "            shape = self.generate_random_shape(image_height, image_width)\n",
    "            shapes.append(shape)\n",
    "            x, y, width, height = shape.bounding_box\n",
    "            boxes.append((x, y, x + width, y + width))\n",
    "        # Apply non-max suppression wit 0.1 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(shapes_count), 0.1)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7vDtCWJ5jfGF"
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(3000, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(300, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWw9D_OgjfGF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "outputId": "861628ac-b4fa-4caa-88ad-9b7c4d5736dc"
   },
   "outputs": [],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 10)\n",
    "for _image_id in image_ids:\n",
    "    image = dataset_train.load_image(_image_id, True)\n",
    "    mask, class_ids = dataset_train.load_mask(_image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)  #, dataset_train.image_info[_image_id]['shapes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yhhk-akJjfGG"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5S0w3IsRjfGG"
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode='training', config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "id": "9Zn7lJnNjfGH"
   },
   "outputs": [],
   "source": [
    "# Start with coco weights\n",
    "init_with = 'coco'\n",
    "\n",
    "if init_with == 'imagenet':\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == 'coco':\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=['mrcnn_class_logits', 'mrcnn_bbox_fc',\n",
    "                                'mrcnn_bbox', 'mrcnn_mask'])\n",
    "elif init_with == 'last':\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6z_l3e6jfGH"
   },
   "source": [
    "## Training\n",
    "\n",
    "Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "id": "rg5DJ-7yjfGH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5938fbb7-9c0f-4677-b7eb-9d56aebe9822"
   },
   "outputs": [],
   "source": [
    "# Train the head branches\n",
    "# Passing layers='heads' freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=100,\n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0LZgtXBZjfGJ"
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "model_path = os.path.join(MODEL_DIR, 'vectoraizer.h5')\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhgc87-SjfGJ"
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kCfeFHeFjfGK"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode='inference',\n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, '.h5 file name here')\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print('Loading weights from ', model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEk-y4wsjfGK"
   },
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "_image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                                                                   _image_id)\n",
    "\n",
    "log('original_image', original_image)\n",
    "log('image_meta', image_meta)\n",
    "log('gt_class_id', gt_class_id)\n",
    "log('gt_bbox', gt_bbox)\n",
    "log('gt_mask', gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ra0wLKAkjfGL"
   },
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOfr46WjjfGL"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A840jgD8jfGL"
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "IoUs = []\n",
    "for _image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(dataset_val, inference_config, _image_id,\n",
    "                                                                              use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                                         r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "    IoUs.append(overlaps)\n",
    "    APs.append(AP)\n",
    "\n",
    "print('IoUs: ', IoUs)\n",
    "print('mAP: ', np.mean(APs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
